{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d520b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e99ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path='C:\\\\Users\\\\Rishav\\\\Image caption\\\\Images\\\\' \n",
    "images=glob(images_path + '*.jpg')#reading all images ending with jpg\n",
    "#len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a383f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ad5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(6):\n",
    "    plt.figure()\n",
    "    img=cv2.imread(images[i])\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)#showing the images by converting in to RGB first\n",
    "   # plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa5f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50 #downloding ResNet50\n",
    "incept_model=ResNet50(include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#incept_model.summary() #summary of ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762404ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "last=incept_model.layers[-2].output\n",
    "modele=Model(inputs=incept_model.inputs,outputs=last)#removing the last layer in the model\n",
    "#modele.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_features={} #data preprocessing Starts\n",
    "count=0\n",
    "for i in images:\n",
    "    img=cv2.imread(i)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)#conerting the given images to RGB\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    \n",
    "    img=img.reshape(1,224,224,3)\n",
    "    pred=modele.predict(img).reshape(2048)#returning the values as 2048 vector\n",
    "     \n",
    "    img_name=i.split('\\\\')[-1] #slicing the image name from path\n",
    "    images_features[img_name]=pred#adding the image feature to the dictionary\n",
    "    \n",
    "    count=count+1\n",
    "    \n",
    "    if count>8000:\n",
    "        break\n",
    "    elif count % 50 == 0:\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_path = 'C:\\\\Users\\\\Rishav\\\\Image caption\\\\captions.txt'#text preprocessing starts\n",
    "captions = open(caption_path, 'rb').read().decode('utf-8').split('\\n')#splitting the captions\n",
    "len(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b14e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_dict = {}\n",
    "for i in captions:\n",
    "    try:\n",
    "        img_name = i.split(',')[0]\n",
    "        caption = i.split(',')[1]\n",
    "        if img_name not in captions_dict:\n",
    "            captions_dict[img_name] = [caption] #assigning keys and values to images\n",
    "                \n",
    "        else:\n",
    "            captions_dict[img_name].append(caption)\n",
    "            \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb269c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_dict.pop('Caption','Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f931e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowers(st):\n",
    "    modified=st.lower()\n",
    "    modified=\"start \"+modified+\" end\" #lower case all the values\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in captions_dict.items():\n",
    "    for vv in v:\n",
    "        captions_dict[k][v.index(vv)]=lowers(vv)#looping through all captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91bff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#captions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ace915",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_words={}\n",
    "count=1\n",
    "for k,vv in captions_dict.items():\n",
    "    for v in vv:\n",
    "        for word  in v.split():\n",
    "            if word not in count_words:\n",
    "                count_words[word]=count \n",
    "                count=count+1\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee936c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406770fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,vv in captions_dict.items():\n",
    "    for v in vv:\n",
    "        encoded=[]\n",
    "        for word in v.split():\n",
    "            encoded.append(count_words[word]) #encoding the words\n",
    "            \n",
    "            \n",
    "        captions_dict[k][vv.index(v)]=encoded\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#captions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3a3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=0\n",
    "for k,vv in captions_dict.items():\n",
    "    for v in vv:\n",
    "        if len(v) > MAX_LEN:\n",
    "            MAX_LEN=len(v)#size of encoded sentences \n",
    "MAX_LEN     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4822b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "VOCAB_SIZE = len(count_words)\n",
    "\n",
    "def generator(photo, caption):\n",
    "    n_samples = 0\n",
    "    \n",
    "    X = []#image features here\n",
    "    y_in = []\n",
    "    y_out = []\n",
    "    a=0\n",
    "    for k, vv in caption.items():\n",
    "        for v in vv:\n",
    "            for i in range(1, len(v)):\n",
    "                X.append(photo[k])\n",
    "\n",
    "                in_seq= [v[:i]]\n",
    "                out_seq = v[i]\n",
    "\n",
    "                in_seq = pad_sequences(in_seq, maxlen=MAX_LEN, padding='post', truncating='post')[0]\n",
    "                out_seq = to_categorical([out_seq], num_classes=VOCAB_SIZE)[0]\n",
    "\n",
    "                y_in.append(in_seq)\n",
    "                y_out.append(out_seq)\n",
    "        a=a+1\n",
    "        if a==8000:\n",
    "            break\n",
    "    return X, y_in, y_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fda5098",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_in, y_out = generator(images_features, captions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd4edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f381b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(y_in), len(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y_in = np.array(y_in, dtype='float64')\n",
    "y_out = np.array(y_out, dtype='float64') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y_in.shape, y_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd73860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb7c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "max_len = MAX_LEN\n",
    "vocab_size = len(count_words)\n",
    "\n",
    "image_model = Sequential()\n",
    "\n",
    "image_model.add(Dense(embedding_size, input_shape=(2048,), activation='relu'))\n",
    "image_model.add(RepeatVector(max_len))\n",
    "\n",
    "image_model.summary()\n",
    "\n",
    "language_model = Sequential()\n",
    "\n",
    "language_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_len))\n",
    "language_model.add(LSTM(256, return_sequences=True))\n",
    "language_model.add(TimeDistributed(Dense(embedding_size)))\n",
    "\n",
    "language_model.summary()\n",
    "\n",
    "conca = Concatenate()([image_model.output, language_model.output])\n",
    "x = LSTM(128, return_sequences=True)(conca)\n",
    "x = LSTM(512, return_sequences=False)(x)\n",
    "x = Dense(vocab_size)(x)\n",
    "out = Activation('softmax')(x)\n",
    "model = Model(inputs=[image_model.input, language_model.input], outputs = out)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a00109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976606a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([X, y_in], y_out, batch_size=512, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e56c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"C:\\\\Users\\\\Rishav\\\\Image caption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3d670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d83c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044a921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
